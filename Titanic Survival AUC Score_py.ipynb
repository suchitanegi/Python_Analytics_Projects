{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Class Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who survived the sinking of the Titanic?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this HW is to predict who survived the Titanic sinking in 1912."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Titanic_0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(713, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            141\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          549\n",
       "Embarked         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set description\n",
    "\n",
    "<ul>\n",
    "<li><b>Survived</b>: binary attribute that indicates whether the passenger survived. This is the dependent variable that we will attempt to explain\n",
    "<li><b>Pclass</b>: Ticket class (1 = 1st class, 2 = 2nd class, 3 = 3rd class)\n",
    "<li><b>Age</b>: Passenger age\n",
    "<li><b>SibSp</b>: The amout of the passenger's siblings/spouses aboard the Titanic\n",
    "<li><b>Parch</b>: The amout of the passenger's parents/children aboard the Titanic\n",
    "<li><b>Fare</b>: The ticket fare\n",
    "<li><b>Male</b>: binary attibute that indicates the gender (1=Male, 0=Female)\n",
    "<li><b>Embarked_C</b>: binary attibute that indicates whether the passenger embarked in Cherbourg\n",
    "<li><b>Embarked_Q</b>: binary attibute that indicates whether the passenger embarked in Queenstown\n",
    "<li><b>Embarked_S</b>: binary attibute that indicates whether the passenger embarked in Southampton\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruction\n",
    "\n",
    "Cleaning the data set if necessary. \n",
    "\n",
    "Use everything you know to find a machine learning model to achieve the highest possible AUC score. Two testing sets have been reserved: TestA.csv and TestB.csv. Your homework will be evaluated using these two sets. 75% of the grade will be based on the AUC score on TestA.csv. 25% of the grade will be based on the ranking of the AUC score on TestB.csv among the six groups. To be specific, your grade on TestA.csv will be equal to the final AUC score multiplied by 75, and your grade on TestB.csv will be equal to 5 * (6 - your ranking). You must submit the same model for both sets with clear explanation of your codes. You must include the codes to evaluate your model on TestA.csv and TestB.csv. Failure to do so will result in 20% loss of grades (10% for each test). \n",
    "\n",
    "TestB.csv is private, which means you will never see it. The ranking will be revealed only after next Wed deadline. TestA.csv is semi-private. This means that you have at most one chance everyday for me to check your model performance on TestA.csv using your code, and I will let you know the AUC score and post your score on the discussion board. I will save your notebook file in the same folder with the data files. If your code does not work on my computer, you lose the opportunity on the same day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            141\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          549\n",
       "Embarked         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Mr.' in df.Name[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Title'] = df.Name.apply(lambda x: 'Mr' if 'Mr.' in x\\\n",
    "                            else 'Mrs' if 'Mrs.' in x\\\n",
    "                            else 'Miss' if 'Miss.' in x\\\n",
    "                            else 'Master' if 'Master.' in x\\\n",
    "                            else 'Miss' if 'Ms.' in x\\\n",
    "                            else 'Miss' if 'Mlle.' in x\\\n",
    "                            else 'Master' if 'Master.' in x\\\n",
    "                            else 'Mrs' if 'Mme' in x\\\n",
    "                            else 'Others'\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title\n",
       "Master     31\n",
       "Miss      146\n",
       "Mr        418\n",
       "Mrs       101\n",
       "Others     17\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Title').Title.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     712\n",
       "unique      3\n",
       "top         S\n",
       "freq      517\n",
       "Name: Embarked, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Embarked'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Embarked.fillna('S', inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df,columns=['Embarked'])\n",
    "df = pd.get_dummies(df,columns=['Pclass'])\n",
    "df = pd.get_dummies(df,columns=['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Male'] = df.Sex.apply(lambda x: 1 if x == 'male' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Relative'] = df.SibSp+df.Parch\n",
    "df.groupby('Relative').Survived.mean().plot()\n",
    "df['Relative_dummy'] = df.Relative.apply(lambda x: 1 if (x==1) | (x==2) | (x==3) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_mean = df.Age.mean()\n",
    "df.Age.fillna(age_mean, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Others</th>\n",
       "      <th>Male</th>\n",
       "      <th>Relative</th>\n",
       "      <th>Relative_dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>713.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>357.000000</td>\n",
       "      <td>0.382889</td>\n",
       "      <td>29.811486</td>\n",
       "      <td>0.513324</td>\n",
       "      <td>0.395512</td>\n",
       "      <td>31.989270</td>\n",
       "      <td>0.182328</td>\n",
       "      <td>0.091164</td>\n",
       "      <td>0.726508</td>\n",
       "      <td>0.244039</td>\n",
       "      <td>0.215989</td>\n",
       "      <td>0.539972</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.204769</td>\n",
       "      <td>0.586255</td>\n",
       "      <td>0.141655</td>\n",
       "      <td>0.023843</td>\n",
       "      <td>0.650771</td>\n",
       "      <td>0.908836</td>\n",
       "      <td>0.326788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>205.969658</td>\n",
       "      <td>0.486433</td>\n",
       "      <td>13.010290</td>\n",
       "      <td>1.075861</td>\n",
       "      <td>0.843403</td>\n",
       "      <td>48.878417</td>\n",
       "      <td>0.386386</td>\n",
       "      <td>0.288044</td>\n",
       "      <td>0.446064</td>\n",
       "      <td>0.429818</td>\n",
       "      <td>0.411795</td>\n",
       "      <td>0.498750</td>\n",
       "      <td>0.204074</td>\n",
       "      <td>0.403816</td>\n",
       "      <td>0.492850</td>\n",
       "      <td>0.348941</td>\n",
       "      <td>0.152667</td>\n",
       "      <td>0.477061</td>\n",
       "      <td>1.610654</td>\n",
       "      <td>0.469368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>179.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>357.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.811486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.458300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>535.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>713.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived         Age       SibSp       Parch  \\\n",
       "count   713.000000  713.000000  713.000000  713.000000  713.000000   \n",
       "mean    357.000000    0.382889   29.811486    0.513324    0.395512   \n",
       "std     205.969658    0.486433   13.010290    1.075861    0.843403   \n",
       "min       1.000000    0.000000    0.420000    0.000000    0.000000   \n",
       "25%     179.000000    0.000000   22.000000    0.000000    0.000000   \n",
       "50%     357.000000    0.000000   29.811486    0.000000    0.000000   \n",
       "75%     535.000000    1.000000   35.000000    1.000000    0.000000   \n",
       "max     713.000000    1.000000   80.000000    8.000000    6.000000   \n",
       "\n",
       "             Fare  Embarked_C  Embarked_Q  Embarked_S    Pclass_1    Pclass_2  \\\n",
       "count  713.000000  713.000000  713.000000  713.000000  713.000000  713.000000   \n",
       "mean    31.989270    0.182328    0.091164    0.726508    0.244039    0.215989   \n",
       "std     48.878417    0.386386    0.288044    0.446064    0.429818    0.411795   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      7.895800    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%     14.458300    0.000000    0.000000    1.000000    0.000000    0.000000   \n",
       "75%     31.000000    0.000000    0.000000    1.000000    0.000000    0.000000   \n",
       "max    512.329200    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         Pclass_3  Title_Master  Title_Miss    Title_Mr   Title_Mrs  \\\n",
       "count  713.000000    713.000000  713.000000  713.000000  713.000000   \n",
       "mean     0.539972      0.043478    0.204769    0.586255    0.141655   \n",
       "std      0.498750      0.204074    0.403816    0.492850    0.348941   \n",
       "min      0.000000      0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000      0.000000    0.000000    0.000000    0.000000   \n",
       "50%      1.000000      0.000000    0.000000    1.000000    0.000000   \n",
       "75%      1.000000      0.000000    0.000000    1.000000    0.000000   \n",
       "max      1.000000      1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "       Title_Others        Male    Relative  Relative_dummy  \n",
       "count    713.000000  713.000000  713.000000      713.000000  \n",
       "mean       0.023843    0.650771    0.908836        0.326788  \n",
       "std        0.152667    0.477061    1.610654        0.469368  \n",
       "min        0.000000    0.000000    0.000000        0.000000  \n",
       "25%        0.000000    0.000000    0.000000        0.000000  \n",
       "50%        0.000000    1.000000    0.000000        0.000000  \n",
       "75%        0.000000    1.000000    1.000000        1.000000  \n",
       "max        1.000000    1.000000   10.000000        1.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Fare'] = df.Fare/(1+df.SibSp+df.Parch)\n",
    "df['Fare_Class'] = 0\n",
    "df.loc[ df.Fare<=7.91, 'Fare_Class'] = 0\n",
    "df.loc[(df['Fare'] > 7.91) & (df['Fare'] <= 14.454), 'Fare_Class'] = 1\n",
    "df.loc[(df['Fare'] > 14.454) & (df['Fare'] <= 31), 'Fare_Class'] = 2\n",
    "df.loc[(df['Fare'] > 31) & (df['Fare'] <= 99), 'Fare_Class'] = 3\n",
    "df.loc[(df['Fare'] > 99) & (df['Fare'] <= 250), 'Fare_Class'] = 4\n",
    "df.loc[df['Fare'] > 250, 'Fare_Class'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age_Class'] = 0\n",
    "df.loc[ df['Age'] <= 11, 'Age_Class'] = 0\n",
    "df.loc[(df['Age'] > 11) & (df['Age'] <= 18), 'Age_Class'] = 1\n",
    "df.loc[(df['Age'] > 18) & (df['Age'] <= 22), 'Age_Class'] = 2\n",
    "df.loc[(df['Age'] > 22) & (df['Age'] <= 27), 'Age_Class'] = 3\n",
    "df.loc[(df['Age'] > 27) & (df['Age'] <= 33), 'Age_Class'] = 4\n",
    "df.loc[(df['Age'] > 33) & (df['Age'] <= 40), 'Age_Class'] = 5\n",
    "df.loc[(df['Age'] > 40) & (df['Age'] <= 66), 'Age_Class'] = 6\n",
    "df.loc[df['Age'] > 66, 'Age_Class'] = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Others</th>\n",
       "      <th>Male</th>\n",
       "      <th>Relative</th>\n",
       "      <th>Relative_dummy</th>\n",
       "      <th>Fare_Class</th>\n",
       "      <th>Age_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>Baxter, Mr. Quigg Edmond</td>\n",
       "      <td>male</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17558</td>\n",
       "      <td>123.7604</td>\n",
       "      <td>B58 B60</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>157</td>\n",
       "      <td>1</td>\n",
       "      <td>Lurette, Miss. Elise</td>\n",
       "      <td>female</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17569</td>\n",
       "      <td>146.5208</td>\n",
       "      <td>B80</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>246</td>\n",
       "      <td>1</td>\n",
       "      <td>Fleming, Miss. Margaret</td>\n",
       "      <td>female</td>\n",
       "      <td>29.811486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17421</td>\n",
       "      <td>110.8833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>Young, Miss. Marie Grice</td>\n",
       "      <td>female</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17760</td>\n",
       "      <td>135.6333</td>\n",
       "      <td>C32</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>271</td>\n",
       "      <td>1</td>\n",
       "      <td>Burns, Miss. Elizabeth Margaret</td>\n",
       "      <td>female</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16966</td>\n",
       "      <td>134.5000</td>\n",
       "      <td>E40</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>Ringhini, Mr. Sante</td>\n",
       "      <td>male</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17760</td>\n",
       "      <td>135.6333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>305</td>\n",
       "      <td>1</td>\n",
       "      <td>Bidois, Miss. Rosalie</td>\n",
       "      <td>female</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17757</td>\n",
       "      <td>227.5250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>423</td>\n",
       "      <td>0</td>\n",
       "      <td>Farthing, Mr. John</td>\n",
       "      <td>male</td>\n",
       "      <td>29.811486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17483</td>\n",
       "      <td>221.7792</td>\n",
       "      <td>C95</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>431</td>\n",
       "      <td>1</td>\n",
       "      <td>LeRoy, Miss. Bertha</td>\n",
       "      <td>female</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17761</td>\n",
       "      <td>106.4250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>447</td>\n",
       "      <td>0</td>\n",
       "      <td>Robbins, Mr. Victor</td>\n",
       "      <td>male</td>\n",
       "      <td>29.811486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17757</td>\n",
       "      <td>227.5250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>561</td>\n",
       "      <td>1</td>\n",
       "      <td>Astor, Mrs. John Jacob (Madeleine Talmadge Force)</td>\n",
       "      <td>female</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17757</td>\n",
       "      <td>113.7625</td>\n",
       "      <td>C62 C64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>568</td>\n",
       "      <td>1</td>\n",
       "      <td>Cleaver, Miss. Alice</td>\n",
       "      <td>female</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>574</td>\n",
       "      <td>1</td>\n",
       "      <td>Endres, Miss. Caroline Louise</td>\n",
       "      <td>female</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17757</td>\n",
       "      <td>227.5250</td>\n",
       "      <td>C45</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>585</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived                                               Name  \\\n",
       "95            96         0                           Baxter, Mr. Quigg Edmond   \n",
       "156          157         1                               Lurette, Miss. Elise   \n",
       "245          246         1                            Fleming, Miss. Margaret   \n",
       "260          261         1                           Young, Miss. Marie Grice   \n",
       "270          271         1                    Burns, Miss. Elizabeth Margaret   \n",
       "299          300         0                                Ringhini, Mr. Sante   \n",
       "304          305         1                              Bidois, Miss. Rosalie   \n",
       "422          423         0                                 Farthing, Mr. John   \n",
       "430          431         1                                LeRoy, Miss. Bertha   \n",
       "446          447         0                                Robbins, Mr. Victor   \n",
       "560          561         1  Astor, Mrs. John Jacob (Madeleine Talmadge Force)   \n",
       "567          568         1                               Cleaver, Miss. Alice   \n",
       "573          574         1                      Endres, Miss. Caroline Louise   \n",
       "584          585         1                      Allen, Miss. Elisabeth Walton   \n",
       "\n",
       "        Sex        Age  SibSp  Parch    Ticket      Fare    Cabin  ...  \\\n",
       "95     male  24.000000      0      1  PC 17558  123.7604  B58 B60  ...   \n",
       "156  female  58.000000      0      0  PC 17569  146.5208      B80  ...   \n",
       "245  female  29.811486      0      0     17421  110.8833      NaN  ...   \n",
       "260  female  36.000000      0      0  PC 17760  135.6333      C32  ...   \n",
       "270  female  41.000000      0      0     16966  134.5000      E40  ...   \n",
       "299    male  22.000000      0      0  PC 17760  135.6333      NaN  ...   \n",
       "304  female  42.000000      0      0  PC 17757  227.5250      NaN  ...   \n",
       "422    male  29.811486      0      0  PC 17483  221.7792      C95  ...   \n",
       "430  female  30.000000      0      0  PC 17761  106.4250      NaN  ...   \n",
       "446    male  29.811486      0      0  PC 17757  227.5250      NaN  ...   \n",
       "560  female  18.000000      1      0  PC 17757  113.7625  C62 C64  ...   \n",
       "567  female  22.000000      0      0    113781  151.5500      NaN  ...   \n",
       "573  female  38.000000      0      0  PC 17757  227.5250      C45  ...   \n",
       "584  female  29.000000      0      0     24160  211.3375       B5  ...   \n",
       "\n",
       "     Title_Master  Title_Miss  Title_Mr  Title_Mrs  Title_Others  Male  \\\n",
       "95              0           0         1          0             0     1   \n",
       "156             0           1         0          0             0     0   \n",
       "245             0           1         0          0             0     0   \n",
       "260             0           1         0          0             0     0   \n",
       "270             0           1         0          0             0     0   \n",
       "299             0           0         1          0             0     1   \n",
       "304             0           1         0          0             0     0   \n",
       "422             0           0         1          0             0     1   \n",
       "430             0           1         0          0             0     0   \n",
       "446             0           0         1          0             0     1   \n",
       "560             0           0         0          1             0     0   \n",
       "567             0           1         0          0             0     0   \n",
       "573             0           1         0          0             0     0   \n",
       "584             0           1         0          0             0     0   \n",
       "\n",
       "     Relative  Relative_dummy  Fare_Class  Age_Class  \n",
       "95          1               1           4          3  \n",
       "156         0               0           4          6  \n",
       "245         0               0           4          4  \n",
       "260         0               0           4          5  \n",
       "270         0               0           4          6  \n",
       "299         0               0           4          2  \n",
       "304         0               0           4          6  \n",
       "422         0               0           4          4  \n",
       "430         0               0           4          4  \n",
       "446         0               0           4          4  \n",
       "560         1               1           4          1  \n",
       "567         0               0           4          2  \n",
       "573         0               0           4          5  \n",
       "584         0               0           4          4  \n",
       "\n",
       "[14 rows x 26 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Fare_Class == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df[['Age_Class','SibSp','Parch','Fare_Class','Male','Relative_dummy','Embarked_C','Embarked_Q','Embarked_S',\\\n",
    "       'Pclass_1','Pclass_2','Pclass_3','Title_Mr','Title_Mrs','Title_Master','Title_Miss','Title_Mr','Title_Others']]\n",
    "y= df[['Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.matrix(X.values)\n",
    "y = np.array(y.values).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=6, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('robustscaler',\n",
       "                                        RobustScaler(copy=True,\n",
       "                                                     quantile_range=(25.0,\n",
       "                                                                     75.0),\n",
       "                                                     with_centering=True,\n",
       "                                                     with_scaling=True)),\n",
       "                                       ('gradientboostingclassifier',\n",
       "                                        GradientBoostingClassifier(ccp_alpha=0.0,\n",
       "                                                                   criterion='friedman_mse',\n",
       "                                                                   init=None,\n",
       "                                                                   learning_rate=0.1,\n",
       "                                                                   loss='deviance',\n",
       "                                                                   max_depth=3,\n",
       "                                                                   max_features=None,\n",
       "                                                                   ma...\n",
       "                                                                   validation_fraction=0.1,\n",
       "                                                                   verbose=0,\n",
       "                                                                   warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'gradientboostingclassifier__learning_rate': [0.0008,\n",
       "                                                                       0.001,\n",
       "                                                                       0.0012],\n",
       "                         'gradientboostingclassifier__loss': ['deviance'],\n",
       "                         'gradientboostingclassifier__n_estimators': [1600,\n",
       "                                                                      1800,\n",
       "                                                                      1900]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import RobustScaler \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "#pipe = make_pipeline(PolynomialFeatures(degree = 1), StandardScaler(),\\\n",
    "#                         GradientBoostingClassifier())\n",
    "\n",
    "\n",
    "pipe = make_pipeline(RobustScaler(),\\\n",
    "                       GradientBoostingClassifier())\n",
    "\n",
    "param_grid = {'gradientboostingclassifier__loss': ['deviance'], #'exponential'],\n",
    "             'gradientboostingclassifier__learning_rate' : [0.0008, 0.001, 0.0012],\n",
    "             'gradientboostingclassifier__n_estimators' : [1600, 1800, 1900]}\n",
    "\n",
    "gridGB = GridSearchCV(pipe, param_grid = param_grid, cv = 6, n_jobs = -1, return_train_score = True, scoring='roc_auc')\n",
    "gridGB.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_gradientboostingclassifier__learning_rate</th>\n",
       "      <th>param_gradientboostingclassifier__loss</th>\n",
       "      <th>param_gradientboostingclassifier__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.484683</td>\n",
       "      <td>0.076864</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.001</td>\n",
       "      <td>deviance</td>\n",
       "      <td>1800</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.820270</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038526</td>\n",
       "      <td>1</td>\n",
       "      <td>0.910052</td>\n",
       "      <td>0.909974</td>\n",
       "      <td>0.898714</td>\n",
       "      <td>0.902339</td>\n",
       "      <td>0.891686</td>\n",
       "      <td>0.894665</td>\n",
       "      <td>0.901239</td>\n",
       "      <td>0.007024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.007826</td>\n",
       "      <td>0.194924</td>\n",
       "      <td>0.010392</td>\n",
       "      <td>0.005454</td>\n",
       "      <td>0.001</td>\n",
       "      <td>deviance</td>\n",
       "      <td>1900</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.821772</td>\n",
       "      <td>0.827928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038314</td>\n",
       "      <td>2</td>\n",
       "      <td>0.912598</td>\n",
       "      <td>0.910717</td>\n",
       "      <td>0.898636</td>\n",
       "      <td>0.903402</td>\n",
       "      <td>0.892941</td>\n",
       "      <td>0.894868</td>\n",
       "      <td>0.902194</td>\n",
       "      <td>0.007464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.992971</td>\n",
       "      <td>0.159618</td>\n",
       "      <td>0.008976</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>deviance</td>\n",
       "      <td>1600</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.820571</td>\n",
       "      <td>0.827928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038600</td>\n",
       "      <td>3</td>\n",
       "      <td>0.912922</td>\n",
       "      <td>0.910885</td>\n",
       "      <td>0.898588</td>\n",
       "      <td>0.903978</td>\n",
       "      <td>0.892941</td>\n",
       "      <td>0.894904</td>\n",
       "      <td>0.902370</td>\n",
       "      <td>0.007587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.913942</td>\n",
       "      <td>0.157591</td>\n",
       "      <td>0.007148</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>deviance</td>\n",
       "      <td>1900</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.818769</td>\n",
       "      <td>0.828529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039258</td>\n",
       "      <td>4</td>\n",
       "      <td>0.909291</td>\n",
       "      <td>0.908464</td>\n",
       "      <td>0.897472</td>\n",
       "      <td>0.901265</td>\n",
       "      <td>0.891662</td>\n",
       "      <td>0.893900</td>\n",
       "      <td>0.900342</td>\n",
       "      <td>0.006733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.463294</td>\n",
       "      <td>0.162595</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.001</td>\n",
       "      <td>deviance</td>\n",
       "      <td>1600</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.819069</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039053</td>\n",
       "      <td>5</td>\n",
       "      <td>0.909387</td>\n",
       "      <td>0.909069</td>\n",
       "      <td>0.898390</td>\n",
       "      <td>0.901337</td>\n",
       "      <td>0.891878</td>\n",
       "      <td>0.893936</td>\n",
       "      <td>0.900666</td>\n",
       "      <td>0.006768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "4       2.484683      0.076864         0.007979        0.001411   \n",
       "5       3.007826      0.194924         0.010392        0.005454   \n",
       "6       2.992971      0.159618         0.008976        0.000576   \n",
       "2       2.913942      0.157591         0.007148        0.001340   \n",
       "3       2.463294      0.162595         0.006483        0.000499   \n",
       "\n",
       "  param_gradientboostingclassifier__learning_rate  \\\n",
       "4                                           0.001   \n",
       "5                                           0.001   \n",
       "6                                          0.0012   \n",
       "2                                          0.0008   \n",
       "3                                           0.001   \n",
       "\n",
       "  param_gradientboostingclassifier__loss  \\\n",
       "4                               deviance   \n",
       "5                               deviance   \n",
       "6                               deviance   \n",
       "2                               deviance   \n",
       "3                               deviance   \n",
       "\n",
       "  param_gradientboostingclassifier__n_estimators  \\\n",
       "4                                           1800   \n",
       "5                                           1900   \n",
       "6                                           1600   \n",
       "2                                           1900   \n",
       "3                                           1600   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "4  {'gradientboostingclassifier__learning_rate': ...           0.820270   \n",
       "5  {'gradientboostingclassifier__learning_rate': ...           0.821772   \n",
       "6  {'gradientboostingclassifier__learning_rate': ...           0.820571   \n",
       "2  {'gradientboostingclassifier__learning_rate': ...           0.818769   \n",
       "3  {'gradientboostingclassifier__learning_rate': ...           0.819069   \n",
       "\n",
       "   split1_test_score  ...  std_test_score  rank_test_score  \\\n",
       "4           0.828829  ...        0.038526                1   \n",
       "5           0.827928  ...        0.038314                2   \n",
       "6           0.827928  ...        0.038600                3   \n",
       "2           0.828529  ...        0.039258                4   \n",
       "3           0.828829  ...        0.039053                5   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "4            0.910052            0.909974            0.898714   \n",
       "5            0.912598            0.910717            0.898636   \n",
       "6            0.912922            0.910885            0.898588   \n",
       "2            0.909291            0.908464            0.897472   \n",
       "3            0.909387            0.909069            0.898390   \n",
       "\n",
       "   split3_train_score  split4_train_score  split5_train_score  \\\n",
       "4            0.902339            0.891686            0.894665   \n",
       "5            0.903402            0.892941            0.894868   \n",
       "6            0.903978            0.892941            0.894904   \n",
       "2            0.901265            0.891662            0.893900   \n",
       "3            0.901337            0.891878            0.893936   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "4          0.901239         0.007024  \n",
       "5          0.902194         0.007464  \n",
       "6          0.902370         0.007587  \n",
       "2          0.900342         0.006733  \n",
       "3          0.900666         0.006768  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grid = pd.DataFrame(gridGB.cv_results_)\n",
    "df_grid.sort_values('rank_test_score').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"TestA.csv\")\n",
    "df1.Embarked.fillna('S', inplace = True) \n",
    "df1 = pd.get_dummies(df1,columns=['Embarked'])\n",
    "df1 = pd.get_dummies(df1,columns=['Pclass'])\n",
    "df1['Male'] = df1.Sex.apply(lambda x: 1 if x == 'male' else 0)\n",
    "df1['Relative'] = df1.SibSp+df.Parch\n",
    "df1['Relative_dummy'] = df1.Relative.apply(lambda x: 1 if (x==1) | (x==2) | (x==3) else 0)\n",
    "age_mean = df1.Age.mean()\n",
    "df1.Age.fillna(age_mean, inplace = True)\n",
    "\n",
    "df1['Fare'] = df1.Fare/(1+df1.SibSp+df1.Parch)\n",
    "df1['Fare_Class'] = 0\n",
    "df1.loc[ df1.Fare<=7.91, 'Fare_Class'] = 0\n",
    "df1.loc[(df1['Fare'] > 7.91) & (df1['Fare'] <= 14.454), 'Fare_Class'] = 1\n",
    "df1.loc[(df1['Fare'] > 14.454) & (df1['Fare'] <= 31), 'Fare_Class'] = 2\n",
    "df1.loc[(df1['Fare'] > 31) & (df1['Fare'] <= 99), 'Fare_Class'] = 3\n",
    "df1.loc[(df1['Fare'] > 99) & (df1['Fare'] <= 250), 'Fare_Class'] = 4\n",
    "df1.loc[df1['Fare'] > 250, 'Fare_Class'] = 5\n",
    "\n",
    "df1['Age_Class'] = 0\n",
    "df1.loc[ df1['Age'] <= 11, 'Age_Class'] = 0\n",
    "df1.loc[(df1['Age'] > 11) & (df1['Age'] <= 18), 'Age_Class'] = 1\n",
    "df1.loc[(df1['Age'] > 18) & (df1['Age'] <= 22), 'Age_Class'] = 2\n",
    "df1.loc[(df1['Age'] > 22) & (df1['Age'] <= 27), 'Age_Class'] = 3\n",
    "df1.loc[(df1['Age'] > 27) & (df1['Age'] <= 33), 'Age_Class'] = 4\n",
    "df1.loc[(df1['Age'] > 33) & (df1['Age'] <= 40), 'Age_Class'] = 5\n",
    "df1.loc[(df1['Age'] > 40) & (df1['Age'] <= 66), 'Age_Class'] = 6\n",
    "df1.loc[df['Age'] > 66, 'Age_Class'] = 7\n",
    "\n",
    "df1['Title'] = df1.Name.apply(lambda x: 'Mr' if 'Mr.' in x\\\n",
    "                            else 'Mrs' if 'Mrs.' in x\\\n",
    "                            else 'Miss' if 'Miss.' in x\\\n",
    "                            else 'Master' if 'Master.' in x\\\n",
    "                            else 'Miss' if 'Ms.' in x\\\n",
    "                            else 'Miss' if 'Mlle.' in x\\\n",
    "                            else 'Master' if 'Master.' in x\\\n",
    "                            else 'Mrs' if 'Mme' in x\\\n",
    "                            else 'Others'\n",
    "                           )\n",
    "df1 = pd.get_dummies(df1,columns=['Title'])\n",
    "\n",
    "X1= df1[['Age_Class','SibSp','Parch','Fare_Class','Male','Relative_dummy','Embarked_C','Embarked_Q','Embarked_S',\\\n",
    "       'Pclass_1','Pclass_2','Pclass_3','Title_Mr','Title_Mrs','Title_Master','Title_Miss','Title_Mr','Title_Others']]\n",
    "y1= df1[['Survived']]\n",
    "\n",
    "X1 = np.matrix(X1.values)\n",
    "y1 = np.array(y1.values).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestA AUC score is 0.8994\n"
     ]
    }
   ],
   "source": [
    "accuracy = gridGB.score(X1, y1)\n",
    "print('TestA AUC score is {:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
