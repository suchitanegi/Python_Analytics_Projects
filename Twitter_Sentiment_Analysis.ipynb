{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1 – Sentiment Analysis on Twitter \n",
    "                                                                                                    @author:  Suchita Negi\n",
    "                                                                                                    email id: snegi@scu.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1 : \n",
    "### To use keyword ‘Trump’ to collect the tweets and perform sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all the outputs in a cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection:\n",
    "The data with hashtag **Trump** has been collected using tweepy library in python to access twitter API.\n",
    "The data is saved in text file Trump.txt which contains tweets with hashtag **#Trump**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning:\n",
    "\n",
    "* The trump tweet data file is read using file i/o operators in python.\n",
    "This data is then is then cleaned to remove unwanted words and pattern.\n",
    "* **lower()** function is used to convert all tweets in each line to lower case.\n",
    "* **replace()** function is also used to remove and replace unwanted notations/symbols; replaces the occurrences of a string with another.\n",
    "* **split()** function splits the string in substrings; after the tweets is cleansed the data is split to be stored in a list.\n",
    "* **re** is used to clean data with different patterns and substituted with simpler word for understanding. e.g : pattern like https:// is replaced by word URL.\n",
    "Reference: https://docs.python.org/3/library/re.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading regular expression package to clean pattern in data.\n",
    "\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an empty list to load the tweets with keyword Trump\n",
    "tweet_trump=[]\n",
    "\n",
    "#Open the text file in read mode \n",
    "f_tweet_trump = open('Trump.txt','r')\n",
    "\n",
    "#Cleaning the data in each line of the file.\n",
    "for line in f_tweet_trump:\n",
    "    \n",
    "#Convert all words to lower case and strip new line character .   \n",
    "    line = line.lower()\n",
    "    line = line.strip()\n",
    "    \n",
    "#CLeaning unwanted data pattern from each line.\n",
    "    line = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',line)\n",
    "    line = re.sub('@[^\\s]+','UserName',line)\n",
    "    line = re.sub('[\\s]+', ' ', line)\n",
    "    line = re.sub(r'#([^\\s]+)', '', line)\n",
    "    line = re.sub('((xe1[^\\s]+)|(xe2[^\\s]+)|(x80[^\\s]+)|(xf0[^\\s]+))','',line)\n",
    "    \n",
    "#Cleaning unwanted notations and symbols from each line of data file.   \n",
    "    line = line.replace(\"rt\",\"\").replace(\",\",\"\").replace(\".\",\"\").\\\n",
    "    replace(\":\",\"\").replace(\"!\",\"\").replace(\"$\",\"\").replace(\"?\",\"\").\\\n",
    "    replace(\"'\",\"\").replace('\"',\"\").replace(\"\\\\n\",\"\").replace(\"n\\'\",\"\").\\\n",
    "    replace(\"/\",\"\").replace(\"//\",\"\").replace(\"\\\\\",\"\").replace(\"|\",\"\").\\\n",
    "    replace(\"%\",\"\").replace(\"-\",\"\").replace(\"_\",\"\").replace(\"(\",\"\").replace(')',\"\")\n",
    "    \n",
    "#Split the words in each line and append each word to the list.\n",
    "    for line in line.split():\n",
    "        tweet_trump.append(line)\n",
    "        \n",
    "#Close the file in read mode\n",
    "f_tweet_trump.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b', 'UserName', 'the', 'cha', 'the', 'trump', 'campaign', 'should', 'be', 'plastering', 'absolutely', 'everywhereURL', 'URL', 'UserName', 'regardless', 'of', 'which', 'democrat', 'is', 'the', 'nominee', 'the', 'trump', 'campaign', 'is', 'ready', 'every', 'single', 'aspect', 'to', 'take', 'on', 'any', 'fight', 'we', 'UserName', 'see', 'list', 'of', 'president', 'trump', 'historical', 'and', 'miraculous', 'UserName', 'house', 'of', 'representatives', 'trump', 'has', 'been', 'impeached', 'trump', 'no', 'i', 'haven', 'this', 'is', 'literally', 'trump', 'impeachment', 'defense', 'UserName', 'UserName', 'UserName', 'UserName', 'UserName', 'UserName', 'UserName', 'UserName', 'URL', 'UserName', 'judicial', 'watch', 'files', 'foias', 'on', 'former', 'us', 'ambassador', 'to', 'ukraine', 'marie', 'yovanovitch', 'monitoring', 'of', 'president', 'trump', 'fa', 'on', 'which', 'us', 'senators', 'swear', 'impaiality', 'for', 'trump', 'impeachment', 'trial', 'bursts', 'into', 'flames', 'URL', 'UserName', 'you', 'suppo', 'with', '200+', 'bills', 'sitting', 'unanswered', 'over', 'UserName', 'judicial', 'watch', 'files', 'foias', 'on', 'former', 'us', 'ambassador', 'to', 'ukraine', 'marie', 'yovanovitch', 'monitoring', 'of', 'president', 'trump', 'fa', 'UserName', '51', 'of', 'americans', 'say', 'trump', 'should', 'be', 'removed', 'and', 'i', 'am', 'with', 'that', '51b', 'UserName', 'the', 'cha', 'the', 'trump', 'campaign', 'should', 'be', 'plastering', 'absolutely', 'everywhereURL', 'URL', 'UserName', 'UserName', 'has', 'build', 'a', 'juggernaut', 'of', 'a', 'reelection', 'campaign', 'that', 'continues', 'to', 'build', 'momentumdoesn', 'matter', 'who', 'the', 'trumps', 'next', 'fed', 'chair', 'be', 'a', 'goldbug', 'URL', 'UserName', 'here', 'is', 'the', 'senate', 'organizing', 'resolution', 'governing', 'the', 'trump', 'impeachment', 'trial', 'URL', 'UserName', 'obama', 'nobel', 'peace', 'prizetrump', 'impeachedretweet', 'the', 'truthbUserName', 'UserName', 'payment', 'of', 'debt', 'to', 'barr', 'for', 'alleviating', 'pressures', 'from', 'another', 'trump', 'buddy', 'expiring', 'prematurelybUserName', 'UserName', 'UserName', 'UserName', 'UserName', 'UserName', 'UserName', 'didnt', 'see', 'fox', 'bro', 'URL', 'UserName', 'UserName', 'UserName', 'trumppompeo', 'reveal', 'their', 'perveed', 'solidarity', 'with', 'the', 'people', 'of', 'iran', 'yet', 'againb', 'UserName', 'watch', 'president', 'trump', 'and', 'vp', 'pence', 'visit', 'the', 'main', 'luther', 'king', 'jr', 'memorial', 'in', 'washington', 'dc', 'on', 'URL', 'UserName', 'hows', 'trump', 'gonna', 'claim', 'executive', 'privilege', 'to', 'block', 'lev', 'parnas', 'evidence', 'and', 'testimony', 'while', 'claimin', 'he', 'never', 'met', 'himb', 'UserName', 'i', 'find', 'it', 'hard', 'to', 'expend', 'any', 'energy', 'responding', 'to', 'the', 'trump', 'defense', 'teams', 'impeachment', 'memo', 'because', 'its', 'legally', 'and', 'fact', 'UserName', 'great', 'to', 'be', 'the', 'first', 'instudio', 'guest', 'on', 'UserName', 'new', 'showthank', 'you', 'billb', 'UserName', 'UserName', 'breitba', 'you', 'suppo', 'the', 'impeachment', 'of', 'donald', 'trumpb', 'UserName', 'breaking', 'senate', 'leader', 'mitch', 'mcconnell', 'proposes', 'impeachment', 'trial', 'rules', 'with', 'no', 'guarantee', 'that', 'witnesses', 'will', 'be', 'called', 't', 'UserName', 'lawrence', 'tribe', 'is', 'a', 'reputable', 'lawyerlaw', 'professor', 'you', 'on', 'the', 'other', 'hand', 'are', 'not', 'UserName', 'full', 'stopbwith', 'his', 'defense', 'teams', 'impeachment', 'memorandum', 'trump', 'has', 'shown', 'republicans', 'what', 'he', 'expects', 'of', 'them', 'URL', 'UserName', 'this', 'is', 'meta', 'the', 'president', 'stumbled', '[reading', 'the', 'constitution]', 'trying', 'to', 'get', 'out', 'the', 'wordsthe', 'cameraman', 'tried', 'to', 'UserName', 'i', 'used', 'to', 'think', 'the', 'president', 'for', 'life', 'stuff', 'was', 'an', 'overblown', 'stretch', 'but', 'given', 'his', 'teams', 'current', 'pissing', 'on', 'the', 'constitut', 'like', 'it', 'we', 'would', 'like', 'to', 'invite', 'you', 'to', 'visit', 'our', 'caoons', 'URL', 'UserName', 'thread', 'loesch', 'voted', 'for', '&amp;', 'defends', 'trump', 'who', 'spread', 'a', 'racist', 'smear', 'abt', '1st', 'black', 'potus', 'for', 'yrswno', 'evide', 'UserName', 'thank', 'you', 'for', 'sharing', 'my', 'story', 'i', 'don', 'often', 'talk', 'about', 'the', 'pulse', 'nightclub', 'terrorist', 'attack', 'but', 'it', 'changed', 'my', 'life', 'UserName', 'UserName', 'maga', 'sycophant', 'elise', 'stefanik', 'is', 'out', 'of', 'touch', 'the', 'majority', 'of', 'americans', 'see', 'trump', 'crimes', '&amp;', 'corruption', 'UserName', 'this']\n"
     ]
    }
   ],
   "source": [
    "#Print to display 500 words from the tweets in the list.\n",
    "print(tweet_trump[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference Word List:\n",
    "To proceed with sentiment analysis we require a reference word list to compare our tweet words with.\n",
    "Used reference text file in my directory for positive negative and stop words.\n",
    "We read the below text file and assign these word to a list in python.\n",
    "- positive.txt\n",
    "- negative.txt\n",
    "- stop.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference positive word list.\n",
    "#Convert all words in the file to lower case and append each reference word in the list.\n",
    "positive_words =[]\n",
    "f_positive= open('positive.txt','r')\n",
    "for line in f_positive:\n",
    "    line = line.lower()\n",
    "    line = line.strip()\n",
    "    positive_words.append(line)\n",
    "\n",
    "f_positive.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference negative word list\n",
    "negative_words =[]\n",
    "f_negative= open('negative.txt','r')\n",
    "for line in f_negative:\n",
    "    line = line.lower()\n",
    "    line = line.strip()\n",
    "    negative_words.append(line)\n",
    "\n",
    "f_negative.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference stop word list\n",
    "stop_words =[]\n",
    "f_stop= open('stop.txt','r')\n",
    "for line in f_stop:\n",
    "    line = line.lower()\n",
    "    line = line.strip()\n",
    "    stop_words.append(line)\n",
    "\n",
    "f_stop.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of reference positive words  : 2006 \n",
      "Total number of reference negative words  : 4781 \n",
      "Total number of reference stop words  : 319 \n"
     ]
    }
   ],
   "source": [
    "#To analyze total number of reference words in each list\n",
    "print(\"Total number of reference positive words  : %d \" % len(positive_words))\n",
    "print(\"Total number of reference negative words  : %d \" % len(negative_words))\n",
    "print(\"Total number of reference stop words  : %d \" % len(stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the sentiments\n",
    "We will compare each words in the tweet with reference words, whether positive negative or stop words are present in the tweet list.\n",
    "\n",
    "- Initializing the counter for each sentiment\n",
    "- Comparimg each word with respective word type (postive/negative/stop/others)\n",
    "- Incrementing counter for each word type in tweets if matches with the respective word in reference word list.\n",
    "\n",
    "**Our reference word list contains the word \"trump\" as a positive word.\n",
    "As our search result is based on keyword \"Trump\" , our tweet will consist many trump words which can increase the positive sentiment count.\n",
    "The true sentiment will not be reflected correctly , therefore we increase our positive word count excluding the word \"trump\" i.e. when word is not equal to \"trump\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counter Initialization\n",
    "#positive word count\n",
    "trump_positive_count=0\n",
    "#negative word count\n",
    "trump_negative_count=0\n",
    "#stop word count\n",
    "trump_stop_count= 0\n",
    "#others word count\n",
    "trump_others_count=0\n",
    "\n",
    "#Comparing words in tweets to reference words and incrementing count accordingly\n",
    "\n",
    "for word in tweet_trump:\n",
    "    if word in positive_words and word!=\"trump\":\n",
    "        trump_positive_count += 1 \n",
    "    elif word in negative_words:\n",
    "        trump_negative_count += 1\n",
    "    elif word in stop_words:\n",
    "        trump_stop_count += 1\n",
    "    else:\n",
    "        trump_others_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis:\n",
    "We will Analyze the following:\n",
    "\n",
    "**1. The total positive/negative/stop/other words used in the tweets.**\n",
    "\n",
    "**2. Ratio of positive/negative/stop word/others compare to the whole word count.**\n",
    "\n",
    "**3. Positive to Negative word Ratio.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive words count of tweets : 871\n",
      "Negative words count of tweets : 1196\n",
      "Stop words count of tweets : 15883\n",
      "Other word count of tweets :  21516\n",
      "Whole (Total) word count of tweets : 39466\n",
      "positive v/s negative ratio = 0.73\n"
     ]
    }
   ],
   "source": [
    "# Word counts in tweets\n",
    "\n",
    "#Total number of words in the tweet list\n",
    "trump_whole_word = len(tweet_trump)\n",
    "\n",
    "print(\"Positive words count of tweets : %d\" %trump_positive_count)\n",
    "\n",
    "print(\"Negative words count of tweets : %d\" %trump_negative_count)\n",
    "\n",
    "print(\"Stop words count of tweets : %d\" %trump_stop_count)\n",
    "\n",
    "print(\"Other word count of tweets :  %d\" %trump_others_count)\n",
    "\n",
    "print(\"Whole (Total) word count of tweets : %d\" %trump_whole_word)\n",
    "\n",
    "print(\"positive v/s negative ratio = %.2f\" %(trump_positive_count/trump_negative_count))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of positive words to  whole word count = 0.02\n",
      "Ratio of negative words to  whole word count = 0.03\n",
      "Ratio of stop words to whole word count = 0.40\n",
      "Ratio of other words to whole word count = 0.55\n"
     ]
    }
   ],
   "source": [
    "#Ratio of respecgtive words to total word count\n",
    "\n",
    "print(\"Ratio of positive words to  whole word count = %.2f\" %(trump_positive_count/trump_whole_word))\n",
    "\n",
    "print(\"Ratio of negative words to  whole word count = %.2f\" %(trump_negative_count/trump_whole_word))\n",
    "\n",
    "print(\"Ratio of stop words to whole word count = %.2f\" %(trump_stop_count/trump_whole_word))\n",
    "\n",
    "print(\"Ratio of other words to whole word count = %.2f\" %(trump_others_count/trump_whole_word))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. The sum of all positive/negative sentiments observed.**\n",
    "\n",
    "**5. The general sentiment whether negative or positive.**\n",
    "\n",
    "**6. The sentiment whether weak or strong.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of all positive and negative words in tweets : 2067\n",
      "Difference in all positive and negative words in tweets : 325\n",
      "Percentage of words that are positive: 42.14%\n",
      "Percentage of words that are negative: 57.86%\n",
      "The general sentiment is Negative\n",
      "Negative sentiment is Strong as it is gretater than 50% as compared to positive sentiment.\n",
      "Positive Sentiment is Weak\n"
     ]
    }
   ],
   "source": [
    "#Total number of positive and negative sentiment in the tweets.\n",
    "sum_pos_neg = trump_positive_count + trump_negative_count\n",
    "print(\"Sum of all positive and negative words in tweets : %d\" %(sum_pos_neg))\n",
    "\n",
    "#difference between positive and negative words\n",
    "diff_pos_neg = trump_negative_count - trump_positive_count\n",
    "print(\"Difference in all positive and negative words in tweets : %d\" %(diff_pos_neg))\n",
    "                                                     \n",
    "#Percentage of words that are positive w.r.t sum of positive negative words.\n",
    "percent_positive = (trump_positive_count/sum_pos_neg) * 100\n",
    "\n",
    "#Percentage of words that are negative w.r.t sum of positive negative words.\n",
    "percent_negative = (trump_negative_count/sum_pos_neg) * 100\n",
    "\n",
    "print(\"Percentage of words that are positive: %.2f%%\" %(percent_positive))\n",
    "print(\"Percentage of words that are negative: %.2f%%\" %(percent_negative))\n",
    "\n",
    "#Analyze general sentiment positive/negative and strong or weak.\n",
    "if trump_positive_count>trump_negative_count:\n",
    "    print(\"The general sentiment is Positive\")\n",
    "    if (percent_positive > 50):\n",
    "        print(\"Positive sentiment is Strong as it is gretater than 50% as compared to negative sentiment.\")\n",
    "        print(\"Negative Sentiment is Weak\")\n",
    "else:\n",
    "    print(\"The general sentiment is Negative\")\n",
    "    if (percent_negative > 50):\n",
    "        print(\"Negative sentiment is Strong as it is gretater than 50% as compared to positive sentiment.\")\n",
    "        print(\"Positive Sentiment is Weak\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis:\n",
    "In our analysis we observe that the negative word count used in the tweets(represents negative sentiment) are more than the positive sentiments.\n",
    "The general sentiment in tweets for hashtag \"trump\" is negative and is around **57.86 %** compared to positive sentiments which is around 42.14 %.\n",
    "Also the positive and negative count changes if we include the word trump as a positive word instead of name/hashtag in our tweet.\n",
    "In conclusion sentiments towards this tweet is **strongly negative**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2 : \n",
    "### To use keyword ‘Niners’ to collect the tweets and perform sentiment analysis.\n",
    "We will analyze the twitter sentiments for San francisco 49ers (NINERS) football team who competes in NFL championships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will follow the same steps in our analysis for new keyword \"Niners\" as used above for keyword \"Trump\" .\n",
    "\n",
    "- Data Collection\n",
    "- Data Cleaning\n",
    "- Reference word list\n",
    "- Comapring the sentiments\n",
    "- Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection:\n",
    "The data with hashtag **Niners** has been collected using tweepy library in python to access twitter API.\n",
    "The data is saved in text file Niners.txt which contains tweets with hashtag **#Niners**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an empty list to load the tweets with keyword Niners\n",
    "tweet_niners=[]\n",
    "\n",
    "#Open the text file in read mode \n",
    "f_tweet_niners = open('Niners.txt','r')\n",
    "\n",
    "#Cleaning the data in each line of the file.\n",
    "for line in f_tweet_niners:\n",
    "    \n",
    "#Convert all words to lower case and strip new line character from the file.   \n",
    "    line = line.lower()\n",
    "    line = line.strip()\n",
    "#CLeaning unwanted data pattern from each line.\n",
    "    line = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',line)\n",
    "    line = re.sub('@[^\\s]+','UserName',line)\n",
    "    line = re.sub('[\\s]+', ' ', line)\n",
    "    line = re.sub(r'#([^\\s]+)', '', line)\n",
    "    line = re.sub('((xe1[^\\s]+)|(xe2[^\\s]+)|(x80[^\\s]+)|(xf0[^\\s]+))','',line)\n",
    "    \n",
    "#Cleaning unwanted notations and symbols from each line of data file.   \n",
    "    line = line.replace(\"rt\",\"\").replace(\",\",\"\").replace(\".\",\"\").\\\n",
    "    replace(\":\",\"\").replace(\"!\",\"\").replace(\"$\",\"\").replace(\"?\",\"\").\\\n",
    "    replace(\"'\",\"\").replace('\"',\"\").replace(\"\\\\n\",\"\").replace(\"n\\'\",\"\").\\\n",
    "    replace(\"/\",\"\").replace(\"//\",\"\").replace(\"\\\\\",\"\").replace(\"|\",\"\").\\\n",
    "    replace(\"%\",\"\").replace(\"-\",\"\").replace(\"_\",\"\").replace(\"(\",\"\").replace(')',\"\")\n",
    "    \n",
    "#Split the words in each line and append each word to the list.\n",
    "    for line in line.split():\n",
    "        tweet_niners.append(line)\n",
    "        \n",
    "#Close the file in read mode\n",
    "f_tweet_niners.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bdamn', 'bears', 'are', 'idiots', 'niners', 'have', 'raped', 'them', 'for', 'yearsbUserName', 'UserName', 'UserName', 'UserName', 'it', 'a', 'great', 'sb', 'matchup', 'two', 'passionate', 'fan', 'bases', 'th', 'URL', 'UserName', 'why', 'am', 'i', 'rooting', 'for', 'the', 'the', 'kyle', 'shanahanmike', 'shanahan', 'connection2', 'UserName', 'connection3', 'UserName', 'UserName', 'am', 'i', 'dreamingb', 'UserName', 'i', 'told', 'yall', 'id', 'get', 'yall', 'back', 'to', 'the', 'bowlrichard', 'sherman', 'stuck', 'to', 'his', 'word', 'the', 'niners', 'are', 'nfc', 'champs', 'via', 'UserName', 'UserName', 'barriers', 'going', 'to', 'be', 'broken', 'in', 'miamininers', 'offensive', 'assistant', 'katie', 'sowers', 'will', 'become', 'the', 'first', 'woman', 'to', 'coach', 'in', 'mf', 'niners', 'inna', 'superbowl', 'URL', 'good', 'thing', 'you', 'didn', 'pick', 'my', 'niners', 'but', 'won', 'be', 'long', 'till', 'the', 'drake', 'curse', 'happens', 'and', 'he', 'picks', 'us', 'i', 'be', 'hella', 'madb', 'UserName', 'i', 'told', 'yall', 'id', 'get', 'yall', 'back', 'to', 'the', 'bowlrichard', 'sherman', 'stuck', 'to', 'his', 'word', 'the', 'niners', 'are', 'nfc', 'champs', 'via', 'UserName', 'holden', 'i', 'agree', 'to', 'disagree', 'when', 'it', 'comes', 'to', 'money', 'and', 'spos', 'bets', 'i', 'bet', 'with', 'my', 'head', 'not', 'my', 'hear', 'URL', 'UserName', 'UserName', 'yeah', 'that', 'true', 'peyton', 'did', 'go', 'off', 'that', 'year', 'we', 'have', 'to', 'just', 'wait', 'and', 'see', 'how', 'th', 'URL', 'UserName', 'barriers', 'going', 'to', 'be', 'broken', 'in', 'miamininers', 'offensive', 'assistant', 'katie', 'sowers', 'will', 'become', 'the', 'first', 'woman', 'to', 'coach', 'in', 'deserves', 'itb', 'UserName', 'six', 'years', 'ago', 'today', 'richard', 'sherman', 'had', 'the', 'tip', 'against', 'the', 'niners', 'that', 'sent', 'the', 'seahawks', 'to', 'the', 'super', 'bowlhis', 'late', 'UserName', 'kc', 'is', 'the', '3rd', 'worst', 'team', 'in', 'the', 'nfl', 'against', 'the', 'rush', 'they', 'also', 'can', 'run', 'the', 'ball', 'have', 'URL', 'niners', 'who', 'will', 'wear', 'white', 'jerseys', 'with', 'gold', 'pants', 'are', '20', 'in', 'super', 'bowls', 'with', 'that', 'combination', 'URL', 'UserName', 'they', 'will', 'try', 'to', 'save', 'mahones', 'but', 'the', 'refs', 'wont', 'niners', 'dl', 'will', 'destroy', 'himb', 'UserName', 'jimmy', 'garoppolo', 'in', 'the', 'locker', 'room', 'when', 'the', 'niners', 'win', 'the', 'super', 'bowl', 'URL', 'UserName', 'i', 'told', 'yall', 'id', 'get', 'yall', 'back', 'to', 'the', 'bowlrichard', 'sherman', 'stuck', 'to', 'his', 'word', 'the', 'niners', 'are', 'nfc', 'champs', 'via', 'UserName', 'UserName', 'jimmy', 'garoppolo', 'in', 'the', 'locker', 'room', 'when', 'the', 'niners', 'win', 'the', 'super', 'bowl', 'URL', 'UserName', 'now', 'is', 'the', 'time', 'for', 'me', 'to', 'remind', 'twitter', 'that', 'the', 'are', 'actually', 'the', 'only', 'team', 'in', 'the', 'entire', 'nfl', 'without', 'a', 'skill', 'niners', 'are', 'going', 'to', 'take', 'the', 'super', 'bowl', 'b', 'UserName', 'barriers', 'going', 'to', 'be', 'broken', 'in', 'miamininers', 'offensive', 'assistant', 'katie', 'sowers', 'will', 'become', 'the', 'first', 'woman', 'to', 'coach', 'in', 'spos', 'mediabthe', 'womens', 'world', 'cup', 'was', 'fixed', 'to', 'get', 'the', 'cults', 'repulsive', 'rapinoe', 'to', 'the', 'talk', 'shows', 'and', 'news', 'this', 'looks', 'lik', 'URL', 'UserName', 'niners', 'taking', 'it', 'allbUserName', 'UserName', 'UserName', 'said', 'nobody', 'going', 'to', 'get', 'grounded', 'and', 'pounded', 'go', 'ninersb', 'UserName', 'i', 'told', 'yall', 'id', 'get', 'yall', 'back', 'to', 'the', 'bowlrichard', 'sherman', 'stuck', 'to', 'his', 'word', 'the', 'niners', 'are', 'nfc', 'champs', 'via', 'UserName', 'yea', '49ers', 'moneyline', 'UserName', 'UserName', 'i', 'told', 'yall', 'id', 'get', 'yall', 'back', 'to', 'the', 'bowlrichard', 'sherman', 'stuck', 'to', 'his', 'word', 'the', 'niners', 'are', 'nfc', 'champs', 'via', 'UserName', 'of', 'niner', 'fans', 'all', 'i', 'seen', 'i', 'niners', 'haters', 'come', 'outta', 'hiding', 'UserName', 'UserName', 'UserName', 'chiefs', 'vs', 'niners', 'URL', 'the', 'niners', 'are', 'supposed', 'to']\n"
     ]
    }
   ],
   "source": [
    "#Print to display 500 words from the tweets in the list.\n",
    "print(tweet_niners[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference Word List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference positive word list.\n",
    "#Convert all words in the file to lower case and append each reference word in the list.\n",
    "positive_words =[]\n",
    "f_positive= open('positive.txt','r')\n",
    "for line in f_positive:\n",
    "    line = line.lower()\n",
    "    line = line.strip()\n",
    "    positive_words.append(line)\n",
    "\n",
    "f_positive.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference negative word list\n",
    "negative_words =[]\n",
    "f_negative= open('negative.txt','r')\n",
    "for line in f_negative:\n",
    "    line = line.lower()\n",
    "    line = line.strip()\n",
    "    negative_words.append(line)\n",
    "\n",
    "f_negative.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference stop word list\n",
    "stop_words =[]\n",
    "f_stop= open('stop.txt','r')\n",
    "for line in f_stop:\n",
    "    line = line.lower()\n",
    "    line = line.strip()\n",
    "    stop_words.append(line)\n",
    "\n",
    "f_stop.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of reference positive words  : 2006 \n",
      "Total number of reference negative words  : 4781 \n",
      "Total number of reference stop words  : 319 \n"
     ]
    }
   ],
   "source": [
    "#To analyze total number of reference words in each list\n",
    "print(\"Total number of reference positive words  : %d \" % len(positive_words))\n",
    "print(\"Total number of reference negative words  : %d \" % len(negative_words))\n",
    "print(\"Total number of reference stop words  : %d \" % len(stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the sentiments\n",
    "We will compare each words in the tweet with reference words, whether positive negative or stop words are present in the tweet list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counter Initialization\n",
    "#positive word count\n",
    "niners_positive_count=0\n",
    "#negative word count\n",
    "niners_negative_count=0\n",
    "#stop word count\n",
    "niners_stop_count=0\n",
    "#others word count\n",
    "niners_others_count=0\n",
    "for word in tweet_niners:\n",
    "    if word in positive_words:\n",
    "        niners_positive_count+=1 \n",
    "    elif word in negative_words:\n",
    "            niners_negative_count+=1\n",
    "    elif word in stop_words:\n",
    "            niners_stop_count+=1\n",
    "    else:\n",
    "        niners_others_count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis:\n",
    "We will Analyze the following:\n",
    "\n",
    "**1. The total positive/negative/stop/other words used in the tweets.**\n",
    "\n",
    "**2. Ratio of positive/negative/stop word/others compare to the whole word count.**\n",
    "\n",
    "**3. Positive to Negative word Ratio.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive words count of tweets : 17\n",
      "Negative words count of tweets : 23\n",
      "Stop words count of tweets : 301\n",
      "Other word count of tweets :  373\n",
      "Whole (Total) word count of tweets : 714.00\n",
      "positive v/s negative ratio = 0.74\n"
     ]
    }
   ],
   "source": [
    "# Word counts in tweets\n",
    "\n",
    "#Total number of words in the tweet list\n",
    "niners_whole_word = len(tweet_niners)\n",
    "\n",
    "print(\"Positive words count of tweets : %d\" %niners_positive_count)\n",
    "\n",
    "print(\"Negative words count of tweets : %d\" %niners_negative_count)\n",
    "\n",
    "print(\"Stop words count of tweets : %d\" %niners_stop_count)\n",
    "\n",
    "print(\"Other word count of tweets :  %d\" %niners_others_count)\n",
    "\n",
    "print(\"Whole (Total) word count of tweets : %.2f\" %niners_whole_word)\n",
    "\n",
    "print(\"positive v/s negative ratio = %.2f\" %(niners_positive_count/niners_negative_count))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of positive words to  whole word count = 0.02\n",
      "Ratio of negative words to  whole word count = 0.03\n",
      "Ratio of stop words to whole word count = 0.42\n",
      "Ratio of other words to whole word count = 0.52\n"
     ]
    }
   ],
   "source": [
    "#Ratio of respective words to total word count\n",
    "\n",
    "print(\"Ratio of positive words to  whole word count = %.2f\" %(niners_positive_count/niners_whole_word))\n",
    "\n",
    "print(\"Ratio of negative words to  whole word count = %.2f\" %(niners_negative_count/niners_whole_word))\n",
    "\n",
    "print(\"Ratio of stop words to whole word count = %.2f\" %(niners_stop_count/niners_whole_word))\n",
    "\n",
    "print(\"Ratio of other words to whole word count = %.2f\" %(niners_others_count/niners_whole_word))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. The sum of all positive/negative sentiments observed.**\n",
    "\n",
    "**5. The general sentiment whether negative or positive.**\n",
    "\n",
    "**6. The sentiment whether weak or strong.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of all positive and negative words in tweets : 40\n",
      "Difference in all positive and negative words in tweets : 6\n",
      "Percentage of words that are positive: 42.50%\n",
      "Percentage of words that are negative: 57.50%\n",
      "The general sentiment is Negative\n",
      "Negative sentiment is Strong as it is gretater than 50% as compared to positive sentiment.\n",
      "Positive Sentiment is Weak\n"
     ]
    }
   ],
   "source": [
    "#Total number of positive and negative sentiment in the tweets.\n",
    "sum_pos_neg = niners_positive_count + niners_negative_count\n",
    "print(\"Sum of all positive and negative words in tweets : %d\" %(sum_pos_neg))\n",
    "\n",
    "#difference between positive and negative words\n",
    "diff_pos_neg = niners_negative_count - niners_positive_count\n",
    "print(\"Difference in all positive and negative words in tweets : %d\" %(diff_pos_neg))\n",
    "                                                     \n",
    "#Percentage of words that are positive w.r.t sum of positive negative words.\n",
    "percent_positive = (niners_positive_count/sum_pos_neg) * 100\n",
    "\n",
    "#Percentage of words that are negative w.r.t sum of positive negative words.\n",
    "percent_negative = (niners_negative_count/sum_pos_neg) * 100\n",
    "\n",
    "print(\"Percentage of words that are positive: %.2f%%\" %(percent_positive))\n",
    "print(\"Percentage of words that are negative: %.2f%%\" %(percent_negative))\n",
    "\n",
    "#Analyze general sentiment positive/negative and strong or weak.\n",
    "if niners_positive_count>niners_negative_count:\n",
    "    print(\"The general sentiment is Positive\")\n",
    "    if (percent_positive > 50):\n",
    "        print(\"Positive sentiment is Strong as it is gretater than 50% as compared to negative sentiment.\")\n",
    "        print(\"Negative Sentiment is Weak\")\n",
    "else:\n",
    "    print(\"The general sentiment is Negative\")\n",
    "    if (percent_negative > 50):\n",
    "        print(\"Negative sentiment is Strong as it is gretater than 50% as compared to positive sentiment.\")\n",
    "        print(\"Positive Sentiment is Weak\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis:\n",
    "In our analysis we observe that the negative word count used in the tweets(represents negative sentiment) are more than the positive sentiments.\n",
    "The general sentiment in tweets for hashtag \"Niners\" is negative and is around **57.50 %** compared to positive sentiments which is around 42.50 %.\n",
    "In conclusion sentiments towards this tweet is **strongly negative**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
